{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD2zMZzVeRFF"
      },
      "source": [
        "# Exercise 5a - Imagery Coloring\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s get started by importing the required Python libraries"
      ],
      "metadata": {
        "id": "BohwfBqPsIsq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NWv1HsWxQoYr",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import img_as_uint\n",
        "from skimage.io import imshow, imread\n",
        "from skimage.color import rgb2hsv\n",
        "from skimage.color import rgb2gray"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An image can be thought of as a matrix where every pixel’s color is represented by a number on a scale."
      ],
      "metadata": {
        "id": "dqszuhFgt_mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_1 = np.array([[255, 0, 255],\n",
        "                    [0, 255, 0],\n",
        "                    [255, 0, 255]])\n",
        "imshow(array_1, cmap = 'gray');"
      ],
      "metadata": {
        "id": "hj6FK8yvuACZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although our examples were picking colors on the extreme end of the spectrum, we can also access any of the colors in between.\n",
        "\n",
        "The below image was constructed with the use of the arange function of NumPy and created another image by getting the transpose of the first one."
      ],
      "metadata": {
        "id": "PTeUMA_TuSab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCFn7j2PQoYs"
      },
      "outputs": [],
      "source": [
        "## Arange and Transpose\n",
        "\n",
        "array_spectrum = np.array([np.arange(0,255,17),\n",
        "                   np.arange(255,0,-17),\n",
        "                   np.arange(0,255,17),\n",
        "                   np.arange(255,0,-17)])\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "ax[0].imshow(array_spectrum, cmap = 'gray')\n",
        "ax[0].set_title('Arange Generation')\n",
        "ax[1].imshow(array_spectrum.T, cmap = 'gray')\n",
        "ax[1].set_title('Transpose Generation');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For simplicity we have been using grayscale, but please remember that the machine actually understands colors as different mixtures of Red, Green, and Blue. As such, we can represent images as 3 dimensional matrixes. Each pixel being represented as a Python list that specifies their color mix.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R7a-C3c3u3gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_colors = np.array([[[255, 0, 0],\n",
        "                         [0, 255, 0],\n",
        "                         [0, 0, 255]]])\n",
        "imshow(array_colors);"
      ],
      "metadata": {
        "id": "sK-QSJptwe2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJRc74DsQoYt"
      },
      "source": [
        "# Exercise 5b - Digitizing Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect Google Drive & Reading .csv files"
      ],
      "metadata": {
        "id": "DCNtHkCVdZ6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HBrQ4zPLXXsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7175fbfe-517e-426f-cf09-b035c4365769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "dir = '/content/drive/MyDrive/Colab Notebooks'\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s try manipulating an actual image. Go to GitHub and download \"panda_rgb.png\" and place it into Google Drive:\n",
        "\n",
        "## content/drive/MyDrive/Colab Notebooks"
      ],
      "metadata": {
        "id": "9NjQ8iIFjw4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "panda = imread('/content/drive/MyDrive/Colab Notebooks/panda_rgb.png')\n",
        "imshow(panda)"
      ],
      "metadata": {
        "id": "OQuKsfZ8ctwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for the size of the image, we see that it is a 750 x 1000 x 4 matrix. Remember that using Python we can slice this matrix and represent each section as its own image box."
      ],
      "metadata": {
        "id": "4jrnqPt5zydV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "panda.shape"
      ],
      "metadata": {
        "id": "kS7fe0-fj2EN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa2faf4-df3b-4b60-de99-8181baf3f95c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750, 1000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(6,4), sharey= True)\n",
        "\n",
        "ax[0].imshow(panda[:, 0:333])\n",
        "ax[0].set_title('First Split')\n",
        "\n",
        "ax[1].imshow(panda[:, 333:666])\n",
        "ax[1].set_title('Second Split')\n",
        "\n",
        "ax[2].imshow(panda[:, 666:999])\n",
        "ax[2].set_title('Third Split');\n",
        "\n"
      ],
      "metadata": {
        "id": "r1levgNrj89V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each row represents the specific pixel color, we can actually call each of the numbers individually. The numbers can then give us a representation of the image’s Red, Green, and Blue components."
      ],
      "metadata": {
        "id": "3bkclb6EmxQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(12,4), sharey = True)\n",
        "ax[0].imshow(panda[:,:,0], cmap='Reds')\n",
        "ax[0].set_title('Red')\n",
        "ax[1].imshow(panda[:,:,1], cmap='Greens')\n",
        "ax[1].set_title('Green')\n",
        "ax[2].imshow(panda[:,:,2], cmap='Blues')\n",
        "ax[2].set_title('Blue');"
      ],
      "metadata": {
        "id": "Z4t2m267mwN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, we can convert the image from RGB (Red, Green, Blue) to HSV (Hue, Saturation, Value).\n",
        "\n",
        "This will give us the aforementioned figures for Hue, Saturation, and Value.\n",
        "\n"
      ],
      "metadata": {
        "id": "3NEiUf-X12Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "panda_hsv = rgb2hsv(panda)\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12,4), sharey = True)\n",
        "ax[0].imshow(panda_hsv[:,:,0], cmap='hsv')\n",
        "ax[0].set_title('Hue')\n",
        "ax[1].imshow(panda_hsv[:,:,1], cmap='gray')\n",
        "ax[1].set_title('Saturation')\n",
        "ax[2].imshow(panda_hsv[:,:,2], cmap='gray')\n",
        "ax[2].set_title('Value');"
      ],
      "metadata": {
        "id": "FYj6VDagknWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also convert the image matrix to grayscale. By we transform the image to a simple 2x2 matrix. This allows us to easily filter our image based on each pixel’s relation to a specified value."
      ],
      "metadata": {
        "id": "fDtUhwNKnREb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "panda_gray = rgb2gray(panda)\n",
        "fig, ax = plt.subplots(1, 5, figsize=(17,6), sharey = True)\n",
        "ax[0].imshow(panda_gray, cmap = 'gray')\n",
        "ax[0].set_title('Grayscale Original')\n",
        "ax[1].imshow(img_as_uint(panda_gray > 0.25),\n",
        "             cmap = 'gray')\n",
        "ax[1].set_title('Greater than 0.25')\n",
        "ax[2].imshow(img_as_uint(panda_gray > 0.50),\n",
        "             cmap = 'gray')\n",
        "ax[2].set_title('Greater than 0.50');\n",
        "ax[3].imshow(img_as_uint(panda_gray > 0.75),\n",
        "             cmap = 'gray')\n",
        "ax[3].set_title('Greater than 0.75');\n",
        "ax[4].imshow(img_as_uint(panda_gray > np.mean(panda_gray)),\n",
        "             cmap = 'gray')\n",
        "ax[4].set_title('Greater than Mean');"
      ],
      "metadata": {
        "id": "wYrgaakxnO82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5.1 (Do it together) Zoom-in to Panda"
      ],
      "metadata": {
        "id": "nnJ296bxkxe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to zoom in to Panda's face with python code\n",
        "\n",
        "** Q&A: At which x[] and y[] coordinate can we capture the best Panda's face photo?\n",
        "\n",
        "Try to turn panda's photo into Red Color"
      ],
      "metadata": {
        "id": "efYUmZss00Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(panda[yy:yy, xx:xx]);\n"
      ],
      "metadata": {
        "id": "aravumiplOGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5.2 (Do it together) Zoom-in to yourself in Ocean Park's Photo"
      ],
      "metadata": {
        "id": "XxSpoLCYnoEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to Exercise 5.1, try to zoom in to your face with python code.\n",
        "\n",
        "The Group Photo is in GitHub \"OP_group.png\" and place it into Google Drive to process the image:"
      ],
      "metadata": {
        "id": "2rRmFpJ_6O4e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ulBTqOInXMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5c - GeoTiff Image Classification\n",
        "\n",
        "A GeoTIFF is a standard .tif or image file format that includes additional spatial (georeferencing) information embedded in the .tif file as tags.\n",
        "\n",
        "By tags, it is meant that it has some additional metadata like Spatial extent, CRS, Resolution, etc. along with the pixel values. It is a popular distribution format for satellite and aerial photography imagery.\n",
        "\n",
        "In this exercise, we try to digitize and visualize the Digital Terrain (Elevation) Model from Hong Kong."
      ],
      "metadata": {
        "id": "B_fIKbb8n9hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install rasterio\n",
        "\n",
        "import rasterio as rio\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "with rio.open(\"/content/drive/MyDrive/Colab Notebooks/HK_DTM_100m.tif\") as img :\n",
        "    imgnp= img.read()\n",
        "    imgmeta=img.meta\n",
        "    print(imgnp)\n",
        "\n",
        "imshow(imgnp[0,:,:], vmin = 0, vmax = 1000, cmap = 'jet', alpha = 0.7)\n"
      ],
      "metadata": {
        "id": "20rB5EwWnxUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5.3 (Do it together) Try to plot the elevation in Tai Mo Shan area"
      ],
      "metadata": {
        "id": "S3FuAGl1A1Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "with rio.open(\"/content/drive/MyDrive/Colab Notebooks/HK_DTM_100m.tif\") as img :\n",
        "    imgnp= img.read()\n",
        "    imgmeta=img.meta\n",
        "\n",
        "#elevation = pd.DataFrame(imgnp[0,:,:])\n",
        "#elevation = elevation.iloc[100:250,250:350]\n",
        "#elevation.to_csv('/content/drive/MyDrive/Colab Notebooks/elevation.csv', index=False)\n",
        "\n",
        "elevation = np.array(imgnp[0,:,:])\n",
        "elevation = elevation[yy:yy,xx:xx]\n",
        "print(elevation)\n",
        "\n",
        "imshow(elevation, vmin = 0, vmax = 1000, cmap = 'jet', alpha = 0.7)"
      ],
      "metadata": {
        "id": "L_WV9EHNBKYy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}